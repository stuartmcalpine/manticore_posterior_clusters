{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22b4fa6-f3c0-4006-8d63-c40d63250b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Imports and Setup\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from collections import defaultdict\n",
    "from backend.config_loader import load_config\n",
    "from backend.utils import load_clusters_from_hdf5, load_halo_traces_from_hdf5, get_cluster_trace_info, load_single_cluster_traces\n",
    "from pymanticore.analysis.matplotlib import get_mplstyle_path, ManticoreColors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332eb259-778f-4f45-8729-57d21a23a440",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Configuration Loading\n",
    "config = load_config()\n",
    "\n",
    "print(\"Configuration loaded:\")\n",
    "print(f\"Base directory: {config.global_config.basedir}\")\n",
    "print(f\"Output directory: {config.global_config.output_dir}\")\n",
    "print(f\"Observer coordinates: {config.global_config.observer_coords}\")\n",
    "print(f\"Mode1 - eps: {config.mode1.eps}, min_samples: {config.mode1.min_samples}\")\n",
    "print(f\"Mode2 - target_snapshot: {config.mode2.target_snapshot}, min_cluster_size: {config.mode2.min_cluster_size}\")\n",
    "\n",
    "mnras_style = \"mnras\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f95853-b864-4195-8f28-74d7aa2636a2",
   "metadata": {},
   "source": [
    "# Investigate the `eps` and `min_samples` dependence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25acfbec-1dcf-4e2d-af7f-8614882a9deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell: Load Cluster Data for Different Eps and Min_Samples Values\n",
    "import numpy as np\n",
    "import os\n",
    "from backend.utils import load_clusters_from_hdf5\n",
    "\n",
    "# Define parameter ranges\n",
    "eps_values = [1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 5.5]\n",
    "min_samples_values = [3, 5, 7]\n",
    "\n",
    "# Storage for results\n",
    "eps_min_samples_results = {}\n",
    "\n",
    "for min_samples in min_samples_values:\n",
    "    eps_min_samples_results[min_samples] = {}\n",
    "    \n",
    "    for eps in eps_values:\n",
    "        # Convert eps to filename format (2.5 -> \"2p5\")\n",
    "        eps_str = str(eps).replace('.', 'p')\n",
    "        filename = f\"clusters_eps_{eps_str}_min_samples_{min_samples}.h5\"\n",
    "        \n",
    "        try:\n",
    "            clusters, cluster_metadata = load_clusters_from_hdf5(config.global_config.output_dir, filename=filename)\n",
    "            \n",
    "            # Calculate metrics\n",
    "            n_clusters = len(clusters)\n",
    "            cluster_sizes = [c['cluster_size'] for c in clusters]\n",
    "            mean_cluster_size = np.mean(cluster_sizes) if cluster_sizes else 0\n",
    "            max_cluster_size = max(cluster_sizes) if cluster_sizes else 0\n",
    "            large_clusters = len([s for s in cluster_sizes if s >= 25])\n",
    "            \n",
    "            eps_min_samples_results[min_samples][eps] = {\n",
    "                'n_clusters': n_clusters,\n",
    "                'mean_size': mean_cluster_size,\n",
    "                'max_size': max_cluster_size,\n",
    "                'large_clusters': large_clusters,\n",
    "                'cluster_sizes': cluster_sizes,\n",
    "                'clusters': clusters,\n",
    "                'metadata': cluster_metadata\n",
    "            }\n",
    "            \n",
    "            print(f\"min_samples={min_samples}, eps={eps}: {n_clusters} clusters, mean size={mean_cluster_size:.1f}, max size={max_cluster_size}\")\n",
    "            \n",
    "        except FileNotFoundError:\n",
    "            print(f\"File not found for min_samples={min_samples}, eps={eps}: {filename}\")\n",
    "            eps_min_samples_results[min_samples][eps] = None\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading min_samples={min_samples}, eps={eps}: {e}\")\n",
    "            eps_min_samples_results[min_samples][eps] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb7ce53-a312-4a6e-8be5-909cafcbf232",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell: Plot Number of Clusters vs Eps for Different Min_Samples\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "colors = ['blue', 'red', 'green', 'orange', 'purple']\n",
    "markers = ['o', 's', '^', 'D', 'v']\n",
    "\n",
    "for i, min_samples in enumerate(min_samples_values):\n",
    "    # Extract data for this min_samples value\n",
    "    valid_eps = []\n",
    "    n_clusters_list = []\n",
    "    mean_sizes = []\n",
    "    large_clusters_list = []\n",
    "    \n",
    "    for eps in eps_values:\n",
    "        if eps_min_samples_results[min_samples].get(eps) is not None:\n",
    "            valid_eps.append(eps)\n",
    "            n_clusters_list.append(eps_min_samples_results[min_samples][eps]['n_clusters'])\n",
    "            mean_sizes.append(eps_min_samples_results[min_samples][eps]['mean_size'])\n",
    "            large_clusters_list.append(eps_min_samples_results[min_samples][eps]['large_clusters'])\n",
    "    \n",
    "    if len(valid_eps) > 0:\n",
    "        color = colors[i % len(colors)]\n",
    "        marker = markers[i % len(markers)]\n",
    "        \n",
    "        # Plot 1: Total number of clusters vs eps\n",
    "        ax1.plot(valid_eps, n_clusters_list, color=color, marker=marker, \n",
    "                linewidth=2, markersize=8, label=f'min_samples={min_samples}')\n",
    "        \n",
    "        # Plot 2: Mean cluster size vs eps\n",
    "        ax2.plot(valid_eps, mean_sizes, color=color, marker=marker, \n",
    "                linewidth=2, markersize=8, label=f'min_samples={min_samples}')\n",
    "        \n",
    "        # Plot 3: Large clusters (size >= 25) vs eps\n",
    "        ax3.plot(valid_eps, large_clusters_list, color=color, marker=marker, \n",
    "                linewidth=2, markersize=8, label=f'min_samples={min_samples}')\n",
    "\n",
    "# Configure Plot 1\n",
    "ax1.set_xlabel('Eps (Mpc)')\n",
    "ax1.set_ylabel('Number of Clusters')\n",
    "ax1.set_title('Total Clusters vs Eps')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.legend()\n",
    "\n",
    "# Configure Plot 2\n",
    "ax2.set_xlabel('Eps (Mpc)')\n",
    "ax2.set_ylabel('Mean Cluster Size')\n",
    "ax2.set_title('Mean Cluster Size vs Eps')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.legend()\n",
    "\n",
    "# Configure Plot 3\n",
    "ax3.set_xlabel('Eps (Mpc)')\n",
    "ax3.set_ylabel('Number of Large Clusters (≥25)')\n",
    "ax3.set_title('Large Clusters vs Eps')\n",
    "ax3.grid(True, alpha=0.3)\n",
    "ax3.legend()\n",
    "\n",
    "# Plot 4: Summary table as text\n",
    "ax4.axis('off')\n",
    "table_text = \"Parameter Sweep Summary\\n\\n\"\n",
    "table_text += f\"{'MinSamp':<8} {'Eps':<6} {'N_Clust':<8} {'Mean_Size':<10} {'Large_Clust':<12}\\n\"\n",
    "table_text += \"-\" * 60 + \"\\n\"\n",
    "\n",
    "for min_samples in min_samples_values:\n",
    "    for eps in eps_values:\n",
    "        data = eps_min_samples_results[min_samples].get(eps)\n",
    "        if data is not None:\n",
    "            table_text += f\"{min_samples:<8} {eps:<6} {data['n_clusters']:<8} {data['mean_size']:<10.1f} {data['large_clusters']:<12}\\n\"\n",
    "\n",
    "ax4.text(0.05, 0.95, table_text, transform=ax4.transAxes, fontsize=10, \n",
    "         verticalalignment='top', fontfamily='monospace')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print summary table\n",
    "print(f\"{'MinSamp':<8} {'Eps':<6} {'N_Clusters':<10} {'Mean_Size':<10} {'Large_Clusters':<15}\")\n",
    "print(\"-\" * 60)\n",
    "for min_samples in min_samples_values:\n",
    "    for eps in eps_values:\n",
    "        data = eps_min_samples_results[min_samples].get(eps)\n",
    "        if data is not None:\n",
    "            print(f\"{min_samples:<8} {eps:<6} {data['n_clusters']:<10} {data['mean_size']:<10.1f} {data['large_clusters']:<15}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ae7739-290e-4dfb-9879-cfc389704cd0",
   "metadata": {},
   "source": [
    "# Load haloes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a14c38-f79d-4aa2-bcef-0b26a8ca883f",
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 2.0\n",
    "min_samples = 5\n",
    "\n",
    "# Convert eps to filename format (2.5 -> \"2p5\")\n",
    "eps_str = str(eps).replace('.', 'p')\n",
    "filename = f\"clusters_eps_{eps_str}_min_samples_{min_samples}.h5\"\n",
    "\n",
    "clusters, cluster_metadata = load_clusters_from_hdf5(config.global_config.output_dir, filename=filename,\n",
    "                                                    minimal=False)\n",
    "print(f\"Successfully loaded {len(clusters)} clusters\")\n",
    "clusters_available = True\n",
    "\n",
    "# Check for traces file existence without loading data\n",
    "try:\n",
    "    trace_filepath = os.path.join(config.global_config.output_dir, \"halo_traces.h5\")\n",
    "    if os.path.exists(trace_filepath):\n",
    "        print(\"Halo trace file found\")\n",
    "        traces_available = True\n",
    "    else:\n",
    "        print(\"No halo trace data found. Run Mode 2 for temporal evolution plots.\")\n",
    "        traces_available = False\n",
    "except Exception:\n",
    "    print(\"No halo trace data found. Run Mode 2 for temporal evolution plots.\")\n",
    "    traces_available = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9649780-4025-4760-9963-c5ea3a741dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Data Summary Statistics\n",
    "if clusters_available:\n",
    "    cluster_sizes = [c['cluster_size'] for c in clusters]\n",
    "    \n",
    "    print(\"Cluster Statistics:\")\n",
    "    print(f\"  Total clusters: {len(clusters)}\")\n",
    "    print(f\"  Largest cluster size: {max(cluster_sizes) if cluster_sizes else 0}\")\n",
    "    print(f\"  Mean cluster size: {np.mean(cluster_sizes):.2f}\")\n",
    "    print(f\"  Median cluster size: {np.median(cluster_sizes):.2f}\")\n",
    "    \n",
    "    print(f\"\\nTop 5 clusters by size:\")\n",
    "    sorted_clusters = sorted(clusters, key=lambda x: x['cluster_size'], reverse=True)\n",
    "    for i, cluster in enumerate(sorted_clusters[:5]):\n",
    "        print(f\"  {i+1}. Cluster {cluster['cluster_id']}: {cluster['cluster_size']} members, \"\n",
    "              f\"mass={cluster['mean_mass']:.2e}\")\n",
    "\n",
    "if traces_available:\n",
    "    cluster_trace_counts = get_cluster_trace_info(config.global_config.output_dir)\n",
    "    total_traced_haloes = sum(cluster_trace_counts.values())\n",
    "    \n",
    "    print(f\"\\nTrace Statistics:\")\n",
    "    print(f\"  Total traced haloes: {total_traced_haloes}\")\n",
    "    print(f\"  Clusters with traces: {len(cluster_trace_counts)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbca9a07-aee6-4fe1-8e7d-3b2b2abeb51f",
   "metadata": {},
   "source": [
    "# Cluster sizes\n",
    "\n",
    "## Cluster sizes in random region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac300e8-8186-4f97-b3e8-7564c482df76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# empirical_null_analysis.py\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Load cluster sizes from HDF5 file\n",
    "with h5py.File('output/random_control_clusters.h5', 'r') as f:\n",
    "    cluster_sizes = []\n",
    "    clusters_grp = f['clusters']\n",
    "    for cluster_name in clusters_grp.keys():\n",
    "        cluster_sizes.append(clusters_grp[cluster_name].attrs['cluster_size'])\n",
    "\n",
    "cluster_sizes = np.array(cluster_sizes)\n",
    "\n",
    "# Empirical survival function: P(size >= n)\n",
    "def empirical_survival(n):\n",
    "    return np.mean(cluster_sizes >= n)\n",
    "\n",
    "# Calculate significance thresholds\n",
    "size_range = np.arange(3, max(cluster_sizes) + 1)\n",
    "survival_probs = [empirical_survival(n) for n in size_range]\n",
    "\n",
    "# Find thresholds for different significance levels\n",
    "alpha_levels = [0.1, 0.05, 0.01, 0.001]\n",
    "thresholds = {}\n",
    "\n",
    "for alpha in alpha_levels:\n",
    "    threshold_candidates = [n for n, p in zip(size_range, survival_probs) if p <= alpha]\n",
    "    if threshold_candidates:\n",
    "        thresholds[alpha] = min(threshold_candidates)\n",
    "    else:\n",
    "        thresholds[alpha] = None\n",
    "\n",
    "# Create plots\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# 1. Empirical distribution (linear scale)\n",
    "bins = np.arange(1, max(cluster_sizes) + 2) - 0.5\n",
    "counts, _ = np.histogram(cluster_sizes, bins=bins, density=True)\n",
    "bin_centers = np.arange(1, max(cluster_sizes) + 1)\n",
    "\n",
    "ax1.bar(bin_centers, counts, alpha=0.7, edgecolor='black', width=0.8)\n",
    "ax1.set_xlabel('Cluster Size')\n",
    "ax1.set_ylabel('Probability Density')\n",
    "ax1.set_title(f'Empirical Null Distribution (N={len(cluster_sizes)})')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Add threshold lines\n",
    "colors = ['orange', 'red', 'purple', 'black']\n",
    "for i, (alpha, threshold) in enumerate(thresholds.items()):\n",
    "    if threshold is not None:\n",
    "        ax1.axvline(threshold, color=colors[i], linestyle='--', \n",
    "                   label=f'{(1-alpha)*100:.1f}% threshold: {threshold}')\n",
    "ax1.legend()\n",
    "\n",
    "# 2. Empirical distribution (log scale)\n",
    "ax2.bar(bin_centers, counts, alpha=0.7, edgecolor='black', width=0.8)\n",
    "ax2.set_xlabel('Cluster Size')\n",
    "ax2.set_ylabel('Probability Density')\n",
    "ax2.set_title('Empirical Null Distribution (Log Scale)')\n",
    "ax2.set_yscale('log')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Add threshold lines\n",
    "for i, (alpha, threshold) in enumerate(thresholds.items()):\n",
    "    if threshold is not None:\n",
    "        ax2.axvline(threshold, color=colors[i], linestyle='--', \n",
    "                   label=f'{(1-alpha)*100:.1f}% threshold: {threshold}')\n",
    "ax2.legend()\n",
    "\n",
    "# 3. Survival function (linear scale)\n",
    "ax3.plot(size_range, survival_probs, 'bo-', markersize=4, linewidth=2)\n",
    "ax3.set_xlabel('Cluster Size')\n",
    "ax3.set_ylabel('P(Size ≥ n)')\n",
    "ax3.set_title('Empirical Survival Function')\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# Add significance levels\n",
    "for i, alpha in enumerate(alpha_levels):\n",
    "    ax3.axhline(alpha, color=colors[i], linestyle='--', alpha=0.7,\n",
    "               label=f'α = {alpha}')\n",
    "    if thresholds[alpha] is not None:\n",
    "        ax3.plot(thresholds[alpha], alpha, 'o', color=colors[i], markersize=8)\n",
    "\n",
    "ax3.legend()\n",
    "ax3.set_ylim(0, 1)\n",
    "\n",
    "# 4. Survival function (log scale)\n",
    "ax4.plot(size_range, survival_probs, 'bo-', markersize=4, linewidth=2)\n",
    "ax4.set_xlabel('Cluster Size')\n",
    "ax4.set_ylabel('P(Size ≥ n)')\n",
    "ax4.set_title('Empirical Survival Function (Log Scale)')\n",
    "ax4.set_yscale('log')\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "# Add significance levels\n",
    "for i, alpha in enumerate(alpha_levels):\n",
    "    ax4.axhline(alpha, color=colors[i], linestyle='--', alpha=0.7,\n",
    "               label=f'α = {alpha}')\n",
    "    if thresholds[alpha] is not None:\n",
    "        ax4.plot(thresholds[alpha], alpha, 'o', color=colors[i], markersize=8)\n",
    "\n",
    "ax4.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print summary statistics\n",
    "print(f\"Null Distribution Summary:\")\n",
    "print(f\"Total clusters: {len(cluster_sizes)}\")\n",
    "print(f\"Size range: {min(cluster_sizes)} - {max(cluster_sizes)}\")\n",
    "print(f\"Mean size: {np.mean(cluster_sizes):.2f}\")\n",
    "print(f\"Median size: {np.median(cluster_sizes):.2f}\")\n",
    "\n",
    "print(f\"\\nSignificance Thresholds:\")\n",
    "for alpha in alpha_levels:\n",
    "    if thresholds[alpha] is not None:\n",
    "        confidence = (1 - alpha) * 100\n",
    "        n_expected = empirical_survival(thresholds[alpha]) * len(cluster_sizes)\n",
    "        print(f\"{confidence:5.1f}% confidence (α={alpha:5.3f}): size ≥ {thresholds[alpha]:2d} \"\n",
    "              f\"(p={empirical_survival(thresholds[alpha]):.4f}, {n_expected:.1f} expected)\")\n",
    "    else:\n",
    "        print(f\"{(1-alpha)*100:5.1f}% confidence (α={alpha:5.3f}): No threshold found\")\n",
    "\n",
    "# Detailed tail probabilities\n",
    "print(f\"\\nTail Probabilities:\")\n",
    "for size in range(10, min(30, max(cluster_sizes) + 1), 5):\n",
    "    prob = empirical_survival(size)\n",
    "    expected = prob * len(cluster_sizes)\n",
    "    print(f\"P(size ≥ {size:2d}) = {prob:.4f} ({expected:.1f} expected)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce1efb4-672a-4d49-9a08-ae02013b4cf1",
   "metadata": {},
   "source": [
    "## Cluster sizes from constrained region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759b7a30-29c0-43c9-acef-6f33f4c34192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell: Cluster Size Distribution\n",
    "if clusters_available and len(clusters) > 0:\n",
    "    cluster_sizes = [cluster['cluster_size'] for cluster in clusters]\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    # Linear scale histogram\n",
    "    ax1.hist(cluster_sizes, bins=range(1, max(cluster_sizes) + 2), alpha=0.7, color='steelblue', edgecolor='black', linewidth=0.5)\n",
    "    ax1.set_xlabel('Cluster Size', fontsize=12)\n",
    "    ax1.set_ylabel('Frequency', fontsize=12)\n",
    "    ax1.set_title(f'Cluster Size Distribution (Linear)\\nTotal Clusters: {len(clusters)}', fontsize=14)\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Log scale histogram\n",
    "    ax2.hist(cluster_sizes, bins=range(1, max(cluster_sizes) + 2), alpha=0.7, color='steelblue', edgecolor='black', linewidth=0.5)\n",
    "    ax2.set_xlabel('Cluster Size', fontsize=12)\n",
    "    ax2.set_ylabel('Frequency', fontsize=12)\n",
    "    ax2.set_title('Cluster Size Distribution (Log Scale)', fontsize=14)\n",
    "    ax2.set_yscale('log')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"Cluster size statistics:\")\n",
    "    print(f\"  Total clusters: {len(cluster_sizes)}\")\n",
    "    print(f\"  Mean size: {np.mean(cluster_sizes):.2f}\")\n",
    "    print(f\"  Median size: {np.median(cluster_sizes):.2f}\")\n",
    "    print(f\"  Min size: {min(cluster_sizes)}\")\n",
    "    print(f\"  Max size: {max(cluster_sizes)}\")\n",
    "    print(f\"  Standard deviation: {np.std(cluster_sizes):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c1c828-a642-410d-99d9-e4aed6c14eaf",
   "metadata": {},
   "source": [
    "# Plot cluster locations (overview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d130f747-01a9-4e82-87f4-007a293fef0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "min_members_plot = 40\n",
    "\n",
    "if clusters_available:\n",
    "    with plt.style.context(get_mplstyle_path(mnras_style)):\n",
    "        significant_clusters = [h for h in clusters if h['cluster_size'] >= min_members_plot]\n",
    "        if len(significant_clusters) == 0:\n",
    "            print(f\"No clusters found with at least {min_members_plot} members\")\n",
    "        else:\n",
    "            # ---- FIRST FIGURE: 2D XY and Mollweide projections ----\n",
    "            fig = plt.figure(figsize=(6.5, 3.15))\n",
    "            gs = fig.add_gridspec(1, 2, width_ratios=[1, 2])\n",
    "\n",
    "            ax1 = fig.add_subplot(gs[0, 0])\n",
    "            ax2 = fig.add_subplot(gs[0, 1], projection='mollweide')\n",
    "\n",
    "            tab20_colors = plt.cm.tab20(np.linspace(0, 1, 20))\n",
    "            random.seed(42)\n",
    "            assigned_colors = random.choices(tab20_colors, k=len(significant_clusters))\n",
    "\n",
    "            for i, cluster in enumerate(significant_clusters):\n",
    "                positions = cluster['member_data']['BoundSubhalo/CentreOfMass']\n",
    "                color = assigned_colors[i]\n",
    "                ax1.scatter(positions[:, 0], positions[:, 1], c=[color], s=1, alpha=0.7, marker=\".\")\n",
    "\n",
    "                # Mollweide expects longitude (ra) in [-pi, pi] and latitude (dec) in radians\n",
    "                ra = np.asarray(cluster['member_data']['ra'])\n",
    "                dec = np.asarray(cluster['member_data']['dec'])\n",
    "                ra_wrapped = np.where(ra > 180, ra - 360, ra)  # wrap to [-180, 180]\n",
    "                ra_rad = np.radians(ra_wrapped)\n",
    "                dec_rad = np.radians(dec)\n",
    "                ax2.scatter(ra_rad, dec_rad, c=[color], s=1, alpha=0.7, marker=\".\")\n",
    "\n",
    "            # 2D plot formatting\n",
    "            ax1.set_xlabel('X (Mpc)')\n",
    "            ax1.set_ylabel('Y (Mpc)')\n",
    "            ax1.set_ylim(0,1000)\n",
    "            ax1.set_xlim(0,1000)\n",
    "            circle = plt.Circle((500, 500), 300, fill=False, color='black', linestyle='--', linewidth=2)\n",
    "            ax1.add_patch(circle)\n",
    "            ax1.set_aspect('equal')\n",
    "\n",
    "            # Mollweide formatting\n",
    "            ax2.grid(True, alpha=0.3)\n",
    "            # Set xticks in radians for Mollweide, with labels in degrees\n",
    "            tick_labels = np.arange(-150, 181, 30)\n",
    "            ax2.set_xticks(np.radians(tick_labels))\n",
    "            ax2.set_xticklabels([f\"{tl}°\" for tl in tick_labels])\n",
    "            ax2.set_xlabel('Right Ascension [deg]')\n",
    "            ax2.set_ylabel('Declination [deg]')\n",
    "\n",
    "            plt.tight_layout(pad=0.1)\n",
    "            plt.savefig(\"./plots/posterior_positions.pdf\")\n",
    "            plt.show()\n",
    "            \n",
    "            # ---- SECOND FIGURE: Histogram of Median Distances ----\n",
    "            significant_median_distances = [\n",
    "                np.median(cluster['member_data']['dist'])\n",
    "                for cluster in significant_clusters\n",
    "            ]\n",
    "            fig, ax = plt.subplots(figsize=(3.15, 2.5))\n",
    "            n, bins, patches = ax.hist(significant_median_distances, bins=np.arange(0,510,10),\n",
    "                                       alpha=0.7, edgecolor='black')\n",
    "            bin_centers = (bins[:-1] + bins[1:]) / 2\n",
    "            r_squared_line = bin_centers**2\n",
    "            scaling_factor = 1./900\n",
    "            r_squared_line *= scaling_factor\n",
    "            ax.plot(bin_centers, r_squared_line, 'r--', linewidth=2, label=r'$N \\propto R^2$')\n",
    "            ax.set_xlabel('Median Distance (Mpc)')\n",
    "            ax.set_ylabel('Number of Clusters')\n",
    "            ax.set_ylim(0, 1.1 * np.max(n))\n",
    "            ax.legend()\n",
    "            plt.tight_layout(pad=0.1)\n",
    "            plt.savefig(\"./plots/median_distances.pdf\")\n",
    "            plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceda8be7-326a-4cb1-9614-e246c60757dc",
   "metadata": {},
   "source": [
    "# Helper plot functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340684b4-e835-44f9-a918-6db6b37deba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Cluster Diagnostic Function\n",
    "def plot_cluster_diagnostic(cluster_id=None):\n",
    "    if not clusters_available or len(clusters) == 0:\n",
    "        print(\"No clusters available for diagnostic plot\")\n",
    "        return\n",
    "    \n",
    "    # Find target cluster\n",
    "    if cluster_id is None:\n",
    "        target_cluster = max(clusters, key=lambda x: x['cluster_size'])\n",
    "        cluster_type = \"Largest\"\n",
    "    else:\n",
    "        target_cluster = None\n",
    "        for cluster in clusters:\n",
    "            if cluster['cluster_id'] == cluster_id:\n",
    "                target_cluster = cluster\n",
    "                break\n",
    "        \n",
    "        if target_cluster is None:\n",
    "            print(f\"Cluster ID {cluster_id} not found\")\n",
    "            return\n",
    "        cluster_type = \"Selected\"\n",
    "    \n",
    "    target_cluster_center = target_cluster['mean_position']\n",
    "    target_cluster_id = target_cluster['cluster_id']\n",
    "    \n",
    "    all_positions = []\n",
    "    all_cluster_ids = []\n",
    "    \n",
    "    for cluster in clusters:\n",
    "        positions = cluster['member_data']['BoundSubhalo/CentreOfMass']\n",
    "        cluster_id_val = cluster['cluster_id']\n",
    "        all_positions.extend(positions)\n",
    "        all_cluster_ids.extend([cluster_id_val] * len(positions))\n",
    "    \n",
    "    all_positions = np.array(all_positions)\n",
    "    all_cluster_ids = np.array(all_cluster_ids)\n",
    "    \n",
    "    distances = np.linalg.norm(all_positions - target_cluster_center, axis=1)\n",
    "    within_15mpc = distances <= 15.0\n",
    "    \n",
    "    nearby_positions = all_positions[within_15mpc]\n",
    "    nearby_cluster_labels = all_cluster_ids[within_15mpc]\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "    \n",
    "    unique_labels = np.unique(nearby_cluster_labels)\n",
    "    colors = plt.cm.tab10(np.linspace(0, 1, len(unique_labels)))\n",
    "    \n",
    "    projections = [\n",
    "        (0, 1, 'X', 'Y', 'X-Y'),\n",
    "        (0, 2, 'X', 'Z', 'X-Z'), \n",
    "        (1, 2, 'Y', 'Z', 'Y-Z')\n",
    "    ]\n",
    "    \n",
    "    for ax_idx, (dim1, dim2, label1, label2, proj_name) in enumerate(projections):\n",
    "        ax = axes[ax_idx]\n",
    "        \n",
    "        for i, label in enumerate(unique_labels):\n",
    "            mask = nearby_cluster_labels == label\n",
    "            if label == target_cluster_id:\n",
    "                ax.scatter(nearby_positions[mask, dim1], nearby_positions[mask, dim2], \n",
    "                          c='red', s=80, alpha=0.8, label=f'{cluster_type} Cluster (ID {label})', edgecolors='darkred')\n",
    "            else:\n",
    "                ax.scatter(nearby_positions[mask, dim1], nearby_positions[mask, dim2], \n",
    "                          c=[colors[i]], s=40, alpha=0.6, label=f'Cluster {label}')\n",
    "        \n",
    "        ax.scatter(target_cluster_center[dim1], target_cluster_center[dim2], \n",
    "                  c='black', s=300, marker='*', label='Cluster Center', edgecolors='white', linewidth=2)\n",
    "        \n",
    "        circle = plt.Circle((target_cluster_center[dim1], target_cluster_center[dim2]), \n",
    "                           7.5, fill=False, color='black', linestyle='--', linewidth=2, \n",
    "                           label='7.5 Mpc (eps threshold)')\n",
    "        ax.add_patch(circle)\n",
    "        \n",
    "        ax.set_xlabel(f'{label1} (Mpc)')\n",
    "        ax.set_ylabel(f'{label2} (Mpc)')\n",
    "        ax.set_title(f'{proj_name} projection')\n",
    "        ax.set_aspect('equal')\n",
    "        \n",
    "        if ax_idx == 0:\n",
    "            ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    \n",
    "    fig.suptitle(f'Haloes within 15 Mpc of {cluster_type} Cluster\\n'\n",
    "                f'Cluster Size: {target_cluster[\"cluster_size\"]}, ID: {target_cluster_id}', \n",
    "                fontsize=14)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"{cluster_type} cluster analysis:\")\n",
    "    print(f\"  Cluster ID: {target_cluster_id}\")\n",
    "    print(f\"  Size: {target_cluster['cluster_size']} members\")\n",
    "    print(f\"  Center: [{target_cluster_center[0]:.1f}, {target_cluster_center[1]:.1f}, {target_cluster_center[2]:.1f}]\")\n",
    "    print(f\"  Mean mass: {target_cluster['mean_mass']:.2e}\")\n",
    "    print(f\"  Mass std: {target_cluster['mass_std']:.2e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea580747-329e-488d-9ad4-d0124945a5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8a: Single Cluster Trajectory Plot Function\n",
    "def plot_cluster_trajectory(cluster_id, ax=None):\n",
    "    traces = load_single_cluster_traces(cluster_id, config.global_config.output_dir)\n",
    "    \n",
    "    if traces is None:\n",
    "        print(f\"No traces available for cluster {cluster_id}\")\n",
    "        return None\n",
    "    \n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(12, 12))\n",
    "        standalone = True\n",
    "    else:\n",
    "        standalone = False\n",
    "    \n",
    "    # Calculate cluster centroid from final positions (snapshot 77)\n",
    "    final_positions = []\n",
    "    for trace_data in traces:\n",
    "        positions = trace_data['BoundSubhalo/CentreOfMass']\n",
    "        snapshots = trace_data['snapshots']\n",
    "        final_idx = np.where(snapshots == 77)[0]\n",
    "        if len(final_idx) > 0:\n",
    "            final_positions.append(positions[final_idx[0]])\n",
    "    \n",
    "    if len(final_positions) > 0:\n",
    "        final_positions = np.array(final_positions)\n",
    "        cluster_centroid = np.mean(final_positions, axis=0)\n",
    "    else:\n",
    "        cluster_centroid = np.array([0, 0, 0])\n",
    "    \n",
    "    # Generate colors for each trajectory\n",
    "    colors = plt.cm.tab20(np.linspace(0, 1, min(20, len(traces))))\n",
    "    if len(traces) > 20:\n",
    "        colors = plt.cm.gist_ncar(np.linspace(0, 1, len(traces)))\n",
    "    \n",
    "    for i, trace_data in enumerate(traces):\n",
    "        positions = trace_data['BoundSubhalo/CentreOfMass']\n",
    "        snapshots = trace_data['snapshots']\n",
    "        \n",
    "        # Plot trajectory line\n",
    "        ax.plot(positions[:, 0], positions[:, 1], '-', \n",
    "               alpha=0.5, linewidth=0.8, color=colors[i])\n",
    "        \n",
    "        # Plot start and end points\n",
    "        ax.scatter(positions[0, 0], positions[0, 1], \n",
    "                  c='red', s=40, marker='s', alpha=0.9, \n",
    "                  edgecolors='darkred', linewidth=0.3, zorder=10)\n",
    "        ax.scatter(positions[-1, 0], positions[-1, 1], \n",
    "                  c='blue', s=40, marker='o', alpha=0.9,\n",
    "                  edgecolors='darkblue', linewidth=0.3, zorder=10)\n",
    "    \n",
    "    # Add radial rings at 10 and 20 Mpc\n",
    "    circle_10 = plt.Circle((cluster_centroid[0], cluster_centroid[1]), \n",
    "                          10, fill=False, color='gray', linestyle='--', \n",
    "                          linewidth=1, alpha=0.7)\n",
    "    circle_20 = plt.Circle((cluster_centroid[0], cluster_centroid[1]), \n",
    "                          20, fill=False, color='gray', linestyle=':', \n",
    "                          linewidth=1, alpha=0.7)\n",
    "    ax.add_patch(circle_10)\n",
    "    ax.add_patch(circle_20)\n",
    "    \n",
    "    # Set axis limits to +/- 15 Mpc from cluster centroid\n",
    "    ax.set_xlim(cluster_centroid[0] - 15, cluster_centroid[0] + 15)\n",
    "    ax.set_ylim(cluster_centroid[1] - 15, cluster_centroid[1] + 15)\n",
    "    \n",
    "    ax.set_xlabel('X (Mpc)', fontsize=10)\n",
    "    ax.set_ylabel('Y (Mpc)', fontsize=10)\n",
    "    ax.set_title(f'Cluster {cluster_id} (n={len(traces)})', fontsize=12, pad=10)\n",
    "    ax.set_aspect('equal')\n",
    "    ax.set_facecolor('#f8f8f8')\n",
    "    ax.grid(True, alpha=0.2, linewidth=0.5)\n",
    "    ax.tick_params(labelsize=8)\n",
    "    \n",
    "    if standalone:\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    return traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e04504-dc89-47a4-8841-fdae7b301842",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_cluster_mass_evolution(cluster_id, ax=None):\n",
    "    \"\"\"\n",
    "    Plot the median and 10th–90th percentile range of BoundSubhalo/TotalMass\n",
    "    as a function of snapshot for all haloes in the given cluster.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    cluster_id : int or str\n",
    "        Identifier of the cluster to load.\n",
    "    ax : matplotlib.axes.Axes, optional\n",
    "        Axes in which to plot. If None, creates a new figure + axes.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "    # Load all traces for this cluster\n",
    "    traces = load_single_cluster_traces(cluster_id, config.global_config.output_dir)\n",
    "    if traces is None or len(traces) == 0:\n",
    "        print(f\"No traces available for cluster {cluster_id}\")\n",
    "        return\n",
    "\n",
    "    # Gather all unique snapshot indices present\n",
    "    all_snaps = np.unique(np.concatenate([t['snapshots'] for t in traces]))\n",
    "    all_snaps.sort()\n",
    "\n",
    "    # For each snapshot, collect the masses from each trace (where available)\n",
    "    medians = []\n",
    "    p10 = []\n",
    "    p90 = []\n",
    "\n",
    "    for snap in all_snaps:\n",
    "        masses_at_snap = []\n",
    "        for t in traces:\n",
    "            # find if this trace has the snapshot\n",
    "            idx = np.where(t['snapshots'] == snap)[0]\n",
    "            if idx.size > 0:\n",
    "                masses_at_snap.append(t['BoundSubhalo/TotalMass'][idx[0]])\n",
    "        if len(masses_at_snap) > 0:\n",
    "            arr = np.array(masses_at_snap)\n",
    "            p10.append(np.percentile(arr, 10))\n",
    "            medians.append(np.percentile(arr, 50))\n",
    "            p90.append(np.percentile(arr, 90))\n",
    "        else:\n",
    "            # no data for this snapshot\n",
    "            p10.append(np.nan)\n",
    "            medians.append(np.nan)\n",
    "            p90.append(np.nan)\n",
    "\n",
    "    # Prepare the plot\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(10, 6))\n",
    "        standalone = True\n",
    "    else:\n",
    "        standalone = False\n",
    "\n",
    "    # Convert lists to arrays\n",
    "    all_snaps = np.array(all_snaps)\n",
    "    p10 = np.array(p10)\n",
    "    medians = np.array(medians)\n",
    "    p90 = np.array(p90)\n",
    "\n",
    "    # Plot median line\n",
    "    ax.plot(all_snaps, medians, '-', lw=2, label='Median Mass', color='C0')\n",
    "\n",
    "    # Shade 10th–90th percentile range\n",
    "    ax.fill_between(all_snaps, p10, p90, color='C0', alpha=0.3,\n",
    "                    label='10th–90th percentile')\n",
    "\n",
    "    # Labels & styling\n",
    "    ax.set_xlabel('Snapshot', fontsize=12)\n",
    "    ax.set_ylabel('BoundSubhalo / TotalMass', fontsize=12)\n",
    "    ax.set_title(f'Cluster {cluster_id}: Mass Evolution (n={len(traces)})', pad=10)\n",
    "    ax.grid(True, alpha=0.2)\n",
    "    ax.legend(fontsize=10)\n",
    "    ax.tick_params(labelsize=10)\n",
    "\n",
    "    if standalone:\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e79bd0-7901-4352-9b1c-516055d7e299",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell: Single Cluster Mass Distribution Function\n",
    "def plot_cluster_mass_distribution(cluster_id, ax=None):\n",
    "    if not clusters_available:\n",
    "        print(f\"No clusters available\")\n",
    "        return\n",
    "    \n",
    "    # Find the cluster\n",
    "    target_cluster = None\n",
    "    for cluster in clusters:\n",
    "        if cluster['cluster_id'] == cluster_id:\n",
    "            target_cluster = cluster\n",
    "            break\n",
    "    \n",
    "    if target_cluster is None:\n",
    "        print(f\"Cluster ID {cluster_id} not found\")\n",
    "        return\n",
    "    \n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(10, 6))\n",
    "        standalone = True\n",
    "    else:\n",
    "        standalone = False\n",
    "    \n",
    "    cluster_masses = target_cluster['member_data']['BoundSubhalo/TotalMass']\n",
    "    cluster_size = target_cluster['cluster_size']\n",
    "    median_mass = np.median(cluster_masses)\n",
    "    mean_mass = target_cluster['mean_mass']\n",
    "    \n",
    "    # Plot histogram of masses\n",
    "    ax.hist(cluster_masses, bins=10**np.arange(13.8,15.5,0.05), alpha=0.7, color='skyblue', edgecolor='black', linewidth=0.5)\n",
    "    \n",
    "    # Add vertical lines for mean and median\n",
    "    ax.axvline(mean_mass, color='red', linestyle='--', linewidth=2, alpha=0.8, label=f'Mean: {mean_mass:.2e}')\n",
    "    ax.axvline(median_mass, color='orange', linestyle='-', linewidth=2, alpha=0.8, label=f'Median: {median_mass:.2e}')\n",
    "    \n",
    "    ax.set_xlabel('Mass (M☉)', fontsize=10)\n",
    "    ax.set_ylabel('Frequency', fontsize=10)\n",
    "    ax.set_title(f'Cluster {cluster_id} (n={cluster_size})', fontsize=12, pad=10)\n",
    "    ax.tick_params(labelsize=8)\n",
    "    ax.grid(True, alpha=0.3, linewidth=0.5)\n",
    "    ax.set_xscale(\"log\")\n",
    "    ax.legend(fontsize=8)\n",
    "    \n",
    "    if standalone:\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7207997-66c4-4ac2-950a-c192450e05ca",
   "metadata": {},
   "source": [
    "# Cluster evolutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0dcfdee-d74f-4204-af90-d6b86ddaf573",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Temporal Evolution Setup\n",
    "if traces_available:\n",
    "    cluster_trace_counts = get_cluster_trace_info(config.global_config.output_dir)\n",
    "    \n",
    "    # Filter clusters with sufficient traces\n",
    "    min_traces_for_plot = 5  # Adjustable parameter\n",
    "    significant_trace_clusters = {k: v for k, v in cluster_trace_counts.items() \n",
    "                                 if v >= min_traces_for_plot}\n",
    "    \n",
    "    print(f\"Temporal evolution setup:\")\n",
    "    print(f\"  Total clusters with traces: {len(cluster_trace_counts)}\")\n",
    "    print(f\"  Clusters with >= {min_traces_for_plot} traces: {len(significant_trace_clusters)}\")\n",
    "    \n",
    "    # Sort by number of traces\n",
    "    sorted_trace_clusters = sorted(significant_trace_clusters.items(), \n",
    "                                  key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    print(f\"\\nTop clusters by trace count:\")\n",
    "    for cluster_id, trace_count in sorted_trace_clusters[:10]:\n",
    "        print(f\"  Cluster {cluster_id}: {trace_count} traces\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5130ecba-0cdc-4ac9-bbb0-977b8eb2f5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8b: Top 9 Cluster Trajectory Plots (3x3 Grid)\n",
    "if traces_available and len(significant_trace_clusters) > 0:\n",
    "    # Plot top 9 clusters in 3x3 grid\n",
    "    n_clusters_to_plot = min(9, len(sorted_trace_clusters))\n",
    "    fig, axes = plt.subplots(3, 3, figsize=(20, 20))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for plot_idx in range(n_clusters_to_plot):\n",
    "        cluster_id, trace_count = sorted_trace_clusters[plot_idx]\n",
    "        ax = axes[plot_idx]\n",
    "        plot_cluster_trajectory(cluster_id, ax=ax)\n",
    "    \n",
    "    # Hide unused subplots\n",
    "    for plot_idx in range(n_clusters_to_plot, 9):\n",
    "        axes[plot_idx].set_visible(False)\n",
    "    \n",
    "    # Add overall legend\n",
    "    fig.legend([plt.Line2D([0], [0], marker='s', color='red', linestyle='None', markersize=8, markeredgecolor='darkred'),\n",
    "                plt.Line2D([0], [0], marker='o', color='blue', linestyle='None', markersize=8, markeredgecolor='darkblue'),\n",
    "                plt.Line2D([0], [0], color='gray', alpha=0.6, linewidth=1.0),\n",
    "                plt.Line2D([0], [0], color='gray', linestyle='--', linewidth=1, alpha=0.7),\n",
    "                plt.Line2D([0], [0], color='gray', linestyle=':', linewidth=1, alpha=0.7)],\n",
    "               [f'Snapshot 77 (start)', f'Snapshot {config.mode2.target_snapshot} (end)', 'Halo trajectories', '10 Mpc', '20 Mpc'],\n",
    "               loc='upper center', bbox_to_anchor=(0.5, 0.02), ncol=5, fontsize=12)\n",
    "    \n",
    "    plt.suptitle(f'Top {n_clusters_to_plot} Clusters by Trace Count\\nSnapshot {config.mode2.target_snapshot} to 77', \n",
    "                 fontsize=16, y=0.95)\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(bottom=0.05)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ed3cab-b298-4984-95ca-1389290a65be",
   "metadata": {},
   "source": [
    "# Mass distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a72a02-4cb2-409e-8ade-698d15fb37dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell: Mass Distributions for Clusters Above Size Threshold (5xN Grid)\n",
    "if clusters_available and len(clusters) > 0:\n",
    "    # Set cluster size threshold\n",
    "    cluster_size_threshold = 70  # Adjustable parameter\n",
    "    \n",
    "    # Filter clusters by size\n",
    "    large_clusters = [cluster for cluster in clusters if cluster['cluster_size'] >= cluster_size_threshold]\n",
    "    \n",
    "    if len(large_clusters) == 0:\n",
    "        print(f\"No clusters found with size >= {cluster_size_threshold}\")\n",
    "    else:\n",
    "        # Calculate grid dimensions (5 columns, as many rows as needed)\n",
    "        n_cols = 5\n",
    "        n_rows = (len(large_clusters) + n_cols - 1) // n_cols  # Ceiling division\n",
    "        \n",
    "        fig, axes = plt.subplots(n_rows, n_cols, figsize=(5*n_cols, 5*n_rows))\n",
    "        \n",
    "        # Handle case where there's only one row\n",
    "        if n_rows == 1:\n",
    "            axes = axes.reshape(1, -1)\n",
    "        axes = axes.flatten()\n",
    "        \n",
    "        # Sort by cluster size descending\n",
    "        large_clusters.sort(key=lambda c: c['cluster_size'], reverse=True)\n",
    "        \n",
    "        for plot_idx in range(len(large_clusters)):\n",
    "            cluster = large_clusters[plot_idx]\n",
    "            ax = axes[plot_idx]\n",
    "            plot_cluster_mass_distribution(cluster['cluster_id'], ax=ax)\n",
    "        \n",
    "        # Hide unused subplots\n",
    "        for plot_idx in range(len(large_clusters), n_rows * n_cols):\n",
    "            axes[plot_idx].set_visible(False)\n",
    "        \n",
    "        plt.suptitle(f'Mass Distributions for Clusters with Size >= {cluster_size_threshold}\\n({len(large_clusters)} clusters)', fontsize=18, y=0.95)\n",
    "        plt.tight_layout()\n",
    "        #plt.subplots_adjust(top=0.92)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d785570-b157-4bea-87e1-3f1d7ce27af7",
   "metadata": {},
   "source": [
    "# Inspect individual clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d03d7c-5c9e-4134-850e-9815f09afd7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_id = 256\n",
    "plot_cluster_diagnostic(cluster_id=cluster_id)\n",
    "plot_cluster_mass_distribution(cluster_id=cluster_id)\n",
    "_ = plot_cluster_trajectory(cluster_id=cluster_id)\n",
    "plot_cluster_mass_evolution(cluster_id=cluster_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d8b9aa2-5165-4f2e-a04d-8fb4405c4739",
   "metadata": {},
   "source": [
    "# Save median properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757451b0-59d1-4e1e-a33e-0ea76a319180",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell: Export Simplified Cluster Data\n",
    "import h5py\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Configuration variables\n",
    "min_cluster_size = 25  # Modify this threshold as needed\n",
    "output_filename = \"simplified_clusters.h5\"  # Modify filename as needed\n",
    "\n",
    "if clusters_available and len(clusters) > 0:\n",
    "    # Filter clusters by size threshold\n",
    "    filtered_clusters = [cluster for cluster in clusters if cluster['cluster_size'] >= min_cluster_size]\n",
    "    \n",
    "    if len(filtered_clusters) == 0:\n",
    "        print(f\"No clusters found with size >= {min_cluster_size}\")\n",
    "    else:\n",
    "        print(f\"Processing {len(filtered_clusters)} clusters with size >= {min_cluster_size}\")\n",
    "        \n",
    "        # Get all property keys from first cluster\n",
    "        property_keys = list(filtered_clusters[0]['member_data'].keys())\n",
    "        \n",
    "        # Initialize storage for median values\n",
    "        cluster_ids = []\n",
    "        cluster_sizes = []\n",
    "        median_properties = {}\n",
    "        \n",
    "        # Initialize median property arrays\n",
    "        for key in property_keys:\n",
    "            sample_data = filtered_clusters[0]['member_data'][key]\n",
    "            if len(sample_data.shape) == 1:\n",
    "                # 1D property\n",
    "                median_properties[key] = []\n",
    "            elif len(sample_data.shape) == 2 and sample_data.shape[1] == 3:\n",
    "                # 3D vector property\n",
    "                median_properties[key] = []\n",
    "            else:\n",
    "                # Other multi-dimensional properties\n",
    "                median_properties[key] = []\n",
    "        \n",
    "        # Calculate medians for each cluster\n",
    "        for cluster in filtered_clusters:\n",
    "            cluster_ids.append(cluster['cluster_id'])\n",
    "            cluster_sizes.append(cluster['cluster_size'])\n",
    "            \n",
    "            for key in property_keys:\n",
    "                data = cluster['member_data'][key]\n",
    "                \n",
    "                if len(data.shape) == 1:\n",
    "                    # 1D property - simple median\n",
    "                    median_val = np.nanmedian(data)\n",
    "                    median_properties[key].append(median_val)\n",
    "                elif len(data.shape) == 2 and data.shape[1] == 3:\n",
    "                    # 3D vector - median per component\n",
    "                    median_vec = np.nanmedian(data, axis=0)\n",
    "                    median_properties[key].append(median_vec)\n",
    "                else:\n",
    "                    # Other shapes - median along first axis\n",
    "                    median_val = np.nanmedian(data, axis=0)\n",
    "                    median_properties[key].append(median_val)\n",
    "        \n",
    "        # Convert lists to arrays\n",
    "        cluster_ids = np.array(cluster_ids)\n",
    "        cluster_sizes = np.array(cluster_sizes)\n",
    "        for key in property_keys:\n",
    "            median_properties[key] = np.array(median_properties[key])\n",
    "        \n",
    "        # Save to HDF5\n",
    "        output_path = os.path.join(config.global_config.output_dir, output_filename)\n",
    "        \n",
    "        with h5py.File(output_path, 'w') as f:\n",
    "            # Metadata\n",
    "            meta_grp = f.create_group('metadata')\n",
    "            meta_grp.attrs['threshold_size'] = min_cluster_size\n",
    "            meta_grp.attrs['n_clusters'] = len(filtered_clusters)\n",
    "            meta_grp.attrs['source_file'] = 'clusters.h5'\n",
    "            meta_grp.attrs['total_properties'] = len(property_keys)\n",
    "            \n",
    "            # Copy original metadata if available\n",
    "            if 'cluster_metadata' in locals():\n",
    "                for key, value in cluster_metadata.items():\n",
    "                    if isinstance(value, (int, float, str)):\n",
    "                        meta_grp.attrs[f'original_{key}'] = value\n",
    "                    elif isinstance(value, (list, np.ndarray)):\n",
    "                        meta_grp.attrs[f'original_{key}'] = np.array(value)\n",
    "            \n",
    "            # Cluster data\n",
    "            clusters_grp = f.create_group('clusters')\n",
    "            clusters_grp.create_dataset('cluster_ids', data=cluster_ids)\n",
    "            clusters_grp.create_dataset('cluster_sizes', data=cluster_sizes)\n",
    "            \n",
    "            # Median properties\n",
    "            median_grp = clusters_grp.create_group('median_properties')\n",
    "            for key, data in median_properties.items():\n",
    "                # Convert property name to HDF5-safe format\n",
    "                dataset_name = key.replace('/', '_')\n",
    "                median_grp.create_dataset(dataset_name, data=data)\n",
    "        \n",
    "        print(f\"Saved simplified cluster data to: {output_path}\")\n",
    "        print(f\"Properties included: {len(property_keys)}\")\n",
    "        print(f\"Sample properties: {property_keys[:5]}{'...' if len(property_keys) > 5 else ''}\")\n",
    "        \n",
    "        # Summary statistics\n",
    "        print(f\"\\nSummary:\")\n",
    "        print(f\"  Clusters processed: {len(filtered_clusters)}\")\n",
    "        print(f\"  Size range: {np.min(cluster_sizes)} - {np.max(cluster_sizes)}\")\n",
    "        print(f\"  Mean cluster size: {np.mean(cluster_sizes):.1f}\")\n",
    "        print(f\"  File size: {os.path.getsize(output_path) / 1024**2:.2f} MB\")\n",
    "\n",
    "else:\n",
    "    print(\"No cluster data available. Run Mode 1 first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945ed01f-9d3d-4bb5-a34b-cd58ce6a2a4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "manticore-c7",
   "language": "python",
   "name": "manticore-c7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
